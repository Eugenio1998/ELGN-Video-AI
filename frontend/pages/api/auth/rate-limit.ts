// ðŸ“ pages/api/rate-limit.ts
import LRU from "lru-cache";
import type { NextApiResponse } from "next";

type Options = {
  uniqueTokenPerInterval?: number; // Quantidade mÃ¡xima de IPs Ãºnicos
  interval?: number; // Janela de tempo em milissegundos
  max?: number; // NÃ£o utilizado (reservado para futuras melhorias)
};

/**
 * ðŸš« Middleware de proteÃ§Ã£o por limite de requisiÃ§Ãµes (Rate Limit).
 * Utiliza cache LRU para limitar o nÃºmero de requisiÃ§Ãµes por token/IP.
 */
const rateLimit = (options?: Options) => {
  const tokenCache = new LRU<string, number>({
    max: options?.uniqueTokenPerInterval ?? 500,
    ttl: options?.interval ?? 60 * 1000, // PadrÃ£o: 1 minuto
  });

  return {
    /**
     * Verifica se o token ultrapassou o limite. Rejeita a requisiÃ§Ã£o se excedido.
     */
    check: (
      res: NextApiResponse,
      limit: number,
      token: string
    ): Promise<void> =>
      new Promise((resolve, reject) => {
        // âš™ï¸ Ignora rate-limit no ambiente de desenvolvimento
        if (process.env.NODE_ENV === "development") {
          return resolve();
        }

        const current = tokenCache.get(token) ?? 0;

        if (current >= limit) {
          console.warn(`ðŸš¨ Rate limit excedido para token/IP: ${token}`);
          res.status(429).json({
            error: "Muitas tentativas. Aguarde e tente novamente.",
          });
          return reject(new Error("Rate limit exceeded"));
        }

        tokenCache.set(token, current + 1);
        resolve();
      }),
  };
};

export default rateLimit;
